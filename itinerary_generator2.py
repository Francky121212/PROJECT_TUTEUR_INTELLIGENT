"""Pipeline pour g√©n√©rer des le√ßons personnalis√©es avec Ollama Cloud API.
Ce fichier utilise l'API Ollama Cloud pour le d√©ploiement.
"""
import os
import requests
from typing import List, Optional
from ollama import Client  # Utilise la biblioth√®que officielle

# Configuration de l'API Ollama Cloud
OLLAMA_API_KEY = os.environ.get('OLLAMA_API_KEY', 'fc289982b86c43a8932b374295b7bd7b.fLzWxh3aqp2BQTPMo04iJzKT')
OLLAMA_HOST = "https://ollama.com"

# Nom du mod√®le par d√©faut
DEFAULT_MODEL = "gpt-oss:120b-cloud"  # Mod√®le disponible sur Ollama Cloud
FINETUNED_MODEL = "gpt-oss:120b-cloud"  # Changez si vous avez un mod√®le fine-tun√©

# V√©rifier si on utilise l'API Cloud ou local
USE_CLOUD_API = bool(OLLAMA_API_KEY and OLLAMA_API_KEY != 'your-api-key-here')


def build_prompt(subject: str, level: str, learning_style: str, topics: List[str], duration: Optional[int] = None) -> str:
    """Construit le prompt pour g√©n√©rer la le√ßon personnalis√©e.
    
    Args:
        subject: Le sujet d'√©tude (ex: Math√©matiques, Fran√ßais)
        level: Le niveau scolaire (ex: Primaire, Coll√®ge, Lyc√©e)
        learning_style: Le style d'apprentissage pr√©f√©r√© (Visuel, Auditif, Kinesth√©sique)
        topics: Liste des th√®mes √† couvrir
        duration: Dur√©e de la session en minutes (optionnel)
        
    Returns:
        Le prompt format√©
    """
    topics_text = ", ".join(topics) if topics else "g√©n√©ral"
    
    duration_text = ""
    if duration and duration > 0:
        duration_text = f"\nDur√©e de la session: {duration} minutes."
    
    # Adapter le prompt selon le style d'apprentissage
    style_instructions = {
        "Visuel": "Utilisez des diagrammes, sch√©mas, cartes mentales et exemples visuels. Structurez clairement avec des couleurs et des ic√¥nes.",
        "Auditif": "Expliquez avec des analogies, r√©p√©titions et exemples narratifs. Sugg√©rez des mn√©moniques et des rythmes.",
        "Kinesth√©sique": "Proposez des exercices pratiques, des exp√©riences et des manipulations. Incluez des activit√©s interactives.",
        "Lecture/√âcriture": "Fournissez des textes d√©taill√©s, des listes et des r√©sum√©s √©crits. Encouragez la prise de notes."
    }
    
    style_instruction = style_instructions.get(learning_style, style_instructions["Visuel"])
    
    return (
        f"Vous √™tes un tuteur √©ducatif expert, sp√©cialis√© dans l'enseignement personnalis√©. "
        f"Cr√©ez une le√ßon d√©taill√©e et engageante pour un √©l√®ve de niveau {level} en {subject}. "
        f"Th√®mes √† couvrir: {topics_text}."
        f"{duration_text}\n\n"
        f"Style d'apprentissage de l'√©l√®ve: {learning_style}\n"
        f"{style_instruction}\n\n"
        "La le√ßon doit inclure:\n"
        "üìö **Introduction**: Contextualiser le sujet et expliquer son importance\n"
        "üéØ **Objectifs d'apprentissage**: Ce que l'√©l√®ve saura faire apr√®s la le√ßon\n"
        "üìñ **Contenu principal**: Explications claires avec exemples concrets\n"
        "üí° **Exemples pratiques**: Applications r√©elles et exercices guid√©s\n"
        "‚úèÔ∏è **Exercices**: Questions de compr√©hension et probl√®mes √† r√©soudre\n"
        "üéì **R√©sum√©**: Points cl√©s √† retenir\n"
        "üöÄ **Pour aller plus loin**: Ressources et suggestions d'approfondissement\n\n"
        "Formatez la le√ßon de mani√®re claire et structur√©e avec des sections bien d√©finies. "
        "Adaptez le vocabulaire et les exemples au niveau de l'√©l√®ve. "
        "Rendez la le√ßon interactive et motivante."
    )


def generate_lesson(
    subject: str, 
    level: str, 
    learning_style: str,
    topics: List[str],
    duration: Optional[int] = None,
    model_name: Optional[str] = None
) -> str:
    """G√©n√®re une le√ßon personnalis√©e en utilisant l'API Ollama Cloud.
    
    Args:
        subject: Le sujet d'√©tude
        level: Le niveau scolaire
        learning_style: Le style d'apprentissage
        topics: Liste des th√®mes √† couvrir
        duration: Dur√©e de la session en minutes (optionnel)
        model_name: Le mod√®le √† utiliser (optionnel)
        
    Returns:
        La le√ßon g√©n√©r√©e sous forme de texte
    """
    model_name = model_name or DEFAULT_MODEL
    prompt = build_prompt(subject, level, learning_style, topics, duration)
    
    try:
        # Initialisation du client comme dans la documentation
        client = Client(
            host=OLLAMA_HOST,
            headers={'Authorization': f'Bearer {OLLAMA_API_KEY}'}
        )
        
        response = client.chat(
            model=model_name,
            messages=[{'role': 'user', 'content': prompt}],
            stream=False
        )
        return response['message']['content']
        
    except Exception as e:
        return f"Erreur API: {str(e)}"


def main():
    """Fonction principale pour tester le g√©n√©rateur de le√ßons."""
    # Exemple d'utilisation
    subject = "Math√©matiques"
    level = "Lyc√©e"
    learning_style = "Visuel"
    topics = ["Fonctions", "D√©riv√©es"]
    duration = 60
    
    print("=" * 80)
    print(f"üìö Tuteur √âducatif Personnalis√© - Mode: {'Cloud API' if USE_CLOUD_API else 'Local'}")
    print("=" * 80)
    print(f"Sujet: {subject}")
    print(f"Niveau: {level}")
    print(f"Style d'apprentissage: {learning_style}")
    print(f"Dur√©e: {duration} minutes")
    print(f"Th√®mes: {', '.join(topics)}")
    print("-" * 80)
    
    lesson = generate_lesson(
        subject=subject,
        level=level,
        learning_style=learning_style,
        topics=topics,
        duration=duration,
        model_name=DEFAULT_MODEL
    )
    
    print(lesson)
    print("-" * 80)


if __name__ == "__main__":
    main()